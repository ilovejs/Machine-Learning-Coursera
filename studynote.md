#   Machine Learning
### Week2
####    Programming Exercise
### Week3 Logistic Regression & Regularization
####    Logistic Regression
- ->  problem of Linear Regression for classification
- ->  Logistic Regression (change expression of hypothesis)
- ->  Sigmoid Function (Logistic function) & Decision Boundary
- ->  Cost Function (non-convex -> convex)
- ->  simplify Cost Function, Gradient Descent
- ->  * Advanced Optimization
    *   fminunc
    *   Optimization Algorithm: Gradient descent, Conjugate gradient, BFGS  , L-BFGS
- ->  Multiclass Classification: one vs all
*   Question
    *   1/2m in Cost Function of Linear Regression, where does 1/2 come from?
    *   Logistic Regression Gradient 求导 (形式与Linear Regression相似)
####    Regularization
->  overfitting / underfitting
->  regularized Linear / Logistic Regression
-   normal equation

*   Question
    *   lamda 如何选取, weighted?
    *   lamda 在 normal equation 中
####    Programming Exercise
*   plotting
    *   find index, plot, mark legend in the same order as plot

  

